<repository_structure>
<directory name="cwsi-swsi-et">
    <file>
        <name>recommendations.csv</name>
        <path>recommendations.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>repo_context_extractor.py</name>
        <path>repo_context_extractor.py</path>
        <content>
import os

EXCLUDED_DIRS = {".git", "__pycache__", "node_modules", ".venv"}
FULL_CONTENT_EXTENSIONS = {".py", ".txt", ".dbml", ".yaml"}

def create_file_element(file_path, root_folder):
    relative_path = os.path.relpath(file_path, root_folder)
    file_name = os.path.basename(file_path)
    file_extension = os.path.splitext(file_name)[1]

    file_element = [
        f"    <file>\n        <name>{file_name}</name>\n        <path>{relative_path}</path>\n"
    ]

    if file_extension in FULL_CONTENT_EXTENSIONS:
        file_element.append("        <content>\n")
        try:
            with open(file_path, "r", encoding="utf-8") as file:
                file_element.append(file.read())
        except UnicodeDecodeError:
            file_element.append("Binary or non-UTF-8 content not displayed")
        file_element.append("\n        </content>\n")
    else:
        file_element.append("        <content>Full content not provided</content>\n")

    file_element.append("    </file>\n")
    return "".join(file_element)

def get_repo_structure(root_folder):
    structure = ["<repository_structure>\n"]

    for subdir, dirs, files in os.walk(root_folder):
        dirs[:] = [d for d in dirs if d not in EXCLUDED_DIRS]
        level = subdir.replace(root_folder, "").count(os.sep)
        indent = " " * 4 * level
        relative_subdir = os.path.relpath(subdir, root_folder)

        structure.append(f'{indent}<directory name="{os.path.basename(subdir)}">\n')
        for file in files:
            file_path = os.path.join(subdir, file)
            file_element = create_file_element(file_path, root_folder)
            structure.append(file_element)
        structure.append(f"{indent}</directory>\n")

    structure.append("</repository_structure>\n")
    return "".join(structure)

def main():
    root_folder = os.getcwd()  # Use the current working directory
    output_file = os.path.join(root_folder, "repository_context.txt")

    # Delete the previous output file if it exists
    if os.path.exists(output_file):
        os.remove(output_file)
        print(f"Deleted previous {output_file}")

    repo_structure = get_repo_structure(root_folder)

    with open(output_file, "w", encoding="utf-8") as f:
        f.write(repo_structure)

    print(f"Fresh repository context has been extracted to {output_file}")

if __name__ == "__main__":
    main()
        </content>
    </file>
    <file>
        <name>requirements.txt</name>
        <path>requirements.txt</path>
        <content>
numpy
pandas
matplotlib
seaborn
scikit-fuzzy
pyet
pyyaml
        </content>
    </file>
    <file>
        <name>sensor_mapping.yaml</name>
        <path>sensor_mapping.yaml</path>
        <content>
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  #         CORN FIELDS
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# LINEAR_CORN Field Sensors (Node C)
# Total Sensors: 13 (3 IRT, 10 TDR)
- hash: "001"
  treatment: 3
  plot_number: 5001
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: IRT5001C3xx24
  span: 5
  sdi-12_address: "0"
  depth: 
  node: C
  field: LINEAR_CORN

- hash: "002"
  treatment: 2
  plot_number: 5003
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: IRT5003C2xx24
  span: 5
  sdi-12_address: "1"
  depth: 
  node: C
  field: LINEAR_CORN

- hash: "003"
  treatment: 1
  plot_number: 5010
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: IRT5010C1xx24
  span: 5
  sdi-12_address: "c"
  depth: 
  node: C
  field: LINEAR_CORN

- hash: "004"
  treatment: 2
  plot_number: 5003
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR5003C20624
  span: 5
  sdi-12_address: "3"
  depth: 6
  node: C
  field: LINEAR_CORN

- hash: "005"
  treatment: 2
  plot_number: 5003
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR5003C21824
  span: 5
  sdi-12_address: "4"
  depth: 18
  node: C
  field: LINEAR_CORN

- hash: "006"
  treatment: 2
  plot_number: 5003
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR5003C23024
  span: 5
  sdi-12_address: "5"
  depth: 30
  node: C
  field: LINEAR_CORN

- hash: "007"
  treatment: 1
  plot_number: 5010
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR5010C10624
  span: 5
  sdi-12_address: "6"
  depth: 6
  node: C
  field: LINEAR_CORN

- hash: "008"
  treatment: 1
  plot_number: 5010
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR5010C11824
  span: 5
  sdi-12_address: "7"
  depth: 18
  node: C
  field: LINEAR_CORN

- hash: "009"
  treatment: 1
  plot_number: 5010
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR5010C13024
  span: 5
  sdi-12_address: "8"
  depth: 30
  node: C
  field: LINEAR_CORN

- hash: "010"
  treatment: 4
  plot_number: 5009
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR5009C40624
  span: 5
  sdi-12_address: "9"
  depth: 6
  node: C
  field: LINEAR_CORN

- hash: "011"
  treatment: 4
  plot_number: 5009
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR5009C41824
  span: 5
  sdi-12_address: "a"
  depth: 18
  node: C
  field: LINEAR_CORN

- hash: "012"
  treatment: 4
  plot_number: 5009
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR5009C43024
  span: 5
  sdi-12_address: "b"
  depth: 30
  node: C
  field: LINEAR_CORN

# LINEAR_CORN Field Sensors (Node B)
# Total Sensors: 15 (2 IRT, 13 TDR)
- hash: "013"
  treatment: 1
  plot_number: 5006
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: IRT5006B1xx24
  span: 5
  sdi-12_address: "0"
  depth: 
  node: B
  field: LINEAR_CORN

- hash: "014"
  treatment: 2
  plot_number: 5012
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: IRT5012B2xx24
  span: 5
  sdi-12_address: "1"
  depth: 
  node: B
  field: LINEAR_CORN

- hash: "015"
  treatment: 4
  plot_number: 5007
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR5007B40624
  span: 5
  sdi-12_address: "2"
  depth: 6
  node: B
  field: LINEAR_CORN

- hash: "016"
  treatment: 4
  plot_number: 5007
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR5007B41824
  span: 5
  sdi-12_address: "3"
  depth: 18
  node: B
  field: LINEAR_CORN

- hash: "017"
  treatment: 4
  plot_number: 5007
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR5007B43024
  span: 5
  sdi-12_address: "4"
  depth: 30
  node: B
  field: LINEAR_CORN

- hash: "018"
  treatment: 4
  plot_number: 5007
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR5007B44224
  span: 5
  sdi-12_address: "5"
  depth: 42
  node: B
  field: LINEAR_CORN

- hash: "019"
  treatment: 1
  plot_number: 5006
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR5006B10624
  span: 5
  sdi-12_address: "6"
  depth: 6
  node: B
  field: LINEAR_CORN

- hash: "020"
  treatment: 1
  plot_number: 5006
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR5006B11824
  span: 5
  sdi-12_address: "7"
  depth: 18
  node: B
  field: LINEAR_CORN

- hash: "021"
  treatment: 1
  plot_number: 5006
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR5006B13024
  span: 5
  sdi-12_address: "8"
  depth: 30
  node: B
  field: LINEAR_CORN

- hash: "022"
  treatment: 1
  plot_number: 5006
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR5006B14224
  span: 5
  sdi-12_address: "9"
  depth: 42
  node: B
  field: LINEAR_CORN

- hash: "023"
  treatment: 2
  plot_number: 5012
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR5012B20624
  span: 5
  sdi-12_address: "a"
  depth: 6
  node: B
  field: LINEAR_CORN

- hash: "024"
  treatment: 2
  plot_number: 5012
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR5012B21824
  span: 5
  sdi-12_address: "b"
  depth: 18
  node: B
  field: LINEAR_CORN

- hash: "025"
  treatment: 2
  plot_number: 5012
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR5012B23024
  span: 5
  sdi-12_address: "c"
  depth: 30
  node: B
  field: LINEAR_CORN

# LINEAR_CORN Field Sensors (Node A)
# Total Sensors: 11 (3 IRT, 8 TDR)
- hash: "032"
  treatment: 1
  plot_number: 5023
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: IRT5023A1xx24
  span: 5
  sdi-12_address: "0"
  depth: 
  node: A
  field: LINEAR_CORN

- hash: "033"
  treatment: 3
  plot_number: 5020
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: IRT5020A3xx24
  span: 5
  sdi-12_address: "1"
  depth: 
  node: A
  field: LINEAR_CORN

- hash: "034"
  treatment: 3
  plot_number: 5018
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: IRT5018A3xx24
  span: 5
  sdi-12_address: "9"
  depth: 
  node: A
  field: LINEAR_CORN

- hash: "035"
  treatment: 1
  plot_number: 5023
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: TDR5023A10624
  span: 5
  sdi-12_address: "2"
  depth: 6
  node: A
  field: LINEAR_CORN

- hash: "036"
  treatment: 1
  plot_number: 5023
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: TDR5023A11824
  span: 5
  sdi-12_address: "3"
  depth: 18
  node: A
  field: LINEAR_CORN

- hash: "037"
  treatment: 1
  plot_number: 5023
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: TDR5023A13024
  span: 5
  sdi-12_address: "4"
  depth: 30
  node: A
  field: LINEAR_CORN

- hash: "038"
  treatment: 1
  plot_number: 5023
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: TDR5023A14224
  span: 5
  sdi-12_address: "5"
  depth: 42
  node: A
  field: LINEAR_CORN

- hash: "039"
  treatment: 2
  plot_number: 5026
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: TDR5026A20624
  span: 5
  sdi-12_address: "6"
  depth: 6
  node: A
  field: LINEAR_CORN

- hash: "040"
  treatment: 2
  plot_number: 5026
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: TDR5026A21824
  span: 5
  sdi-12_address: "7"
  depth: 18
  node: A
  field: LINEAR_CORN

- hash: "041"
  treatment: 2
  plot_number: 5026
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: TDR5026A23824
  span: 5
  sdi-12_address: "8"
  depth: 38
  node: A
  field: LINEAR_CORN

- hash: "042"
  treatment: 4
  plot_number: 5027
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: TDR5027A40624
  span: 5
  sdi-12_address: "a"
  depth: 6
  node: A
  field: LINEAR_CORN

- hash: "043"
  treatment: 4
  plot_number: 5027
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: TDR5027A41824
  span: 5
  sdi-12_address: "b"
  depth: 18
  node: A
  field: LINEAR_CORN

- hash: "044"
  treatment: 4
  plot_number: 5027
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: TDR5027A43024
  span: 5
  sdi-12_address: "c"
  depth: 30
  node: A
  field: LINEAR_CORN

  # New entries for DEN and SAP sensors in treatment 1 plots

- hash: "045"
  treatment: 1
  plot_number: 5006
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: DEN5006B1xx24
  span: 5
  node: B
  field: LINEAR_CORN

- hash: "046"
  treatment: 1
  plot_number: 5006
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: SAP5006B1xx24
  span: 5
  node: B
  field: LINEAR_CORN

- hash: "047"
  treatment: 1
  plot_number: 5010
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: DEN5010C1xx24
  span: 5
  node: C
  field: LINEAR_CORN

- hash: "048"
  treatment: 1
  plot_number: 5010
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: SAP5010C1xx24
  span: 5
  node: C
  field: LINEAR_CORN

- hash: "049"
  treatment: 1
  plot_number: 5023
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: DEN5023A1xx24
  span: 5
  node: A
  field: LINEAR_CORN

- hash: "050"
  treatment: 1
  plot_number: 5023
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: SAP5023A1xx24
  span: 5
  node: A
  field: LINEAR_CORN

  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  #         CORN FIELDS
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  #         SOYBEAN FIELDS
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  #         SOYBEAN FIELDS
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

# LINEAR_SOYBEAN Field Sensors (Node A)
# Total Sensors: 8 (2 IRT, 6 TDR)
- hash: "051"
  treatment: 2
  plot_number: 2001
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: IRT2001A2xx24
  span: 5
  sdi-12_address: "0"
  depth: 
  node: A
  field: LINEAR_SOYBEAN

- hash: "052"
  treatment: 2
  plot_number: 2001
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: TDR2001A20624
  span: 5
  sdi-12_address: "2"
  depth: 6
  node: A
  field: LINEAR_SOYBEAN

- hash: "053"
  treatment: 2
  plot_number: 2001
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: TDR2001A21824
  span: 5
  sdi-12_address: "1"
  depth: 18
  node: A
  field: LINEAR_SOYBEAN

- hash: "054"
  treatment: 2
  plot_number: 2001
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: TDR2001A23024
  span: 5
  sdi-12_address: "3"
  depth: 30
  node: A
  field: LINEAR_SOYBEAN

- hash: "055"
  treatment: 4
  plot_number: 2009
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: TDR2009A40624
  span: 5
  sdi-12_address: "4"
  depth: 6
  node: A
  field: LINEAR_SOYBEAN

- hash: "056"
  treatment: 4
  plot_number: 2009
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: TDR2009A41824
  span: 5
  sdi-12_address: "5"
  depth: 18
  node: A
  field: LINEAR_SOYBEAN

- hash: "057"
  treatment: 4
  plot_number: 2009
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: TDR2009A43024
  span: 5
  sdi-12_address: "6"
  depth: 30
  node: A
  field: LINEAR_SOYBEAN

- hash: "058"
  treatment: 3
  plot_number: 2003
  project_id: crop2cloud24
  dataset_id: node_a
  sensor_id: IRT2003A3xx24
  span: 5
  sdi-12_address: "7"
  depth: 
  node: A
  field: LINEAR_SOYBEAN

# LINEAR_SOYBEAN Field Sensors (Node B)
# Total Sensors: 11 (2 IRT, 9 TDR)
- hash: "059"
  treatment: 2
  plot_number: 2011
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: IRT2011B2xx24
  span: 5
  sdi-12_address: "0"
  depth: 
  node: B
  field: LINEAR_SOYBEAN

- hash: "060"
  treatment: 2
  plot_number: 2011
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR2011B20624
  span: 5
  sdi-12_address: "1"
  depth: 6
  node: B
  field: LINEAR_SOYBEAN

- hash: "061"
  treatment: 2
  plot_number: 2011
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR2011B21824
  span: 5
  sdi-12_address: "2"
  depth: 18
  node: B
  field: LINEAR_SOYBEAN

- hash: "062"
  treatment: 2
  plot_number: 2011
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR2011B23024
  span: 5
  sdi-12_address: "3"
  depth: 30
  node: B
  field: LINEAR_SOYBEAN

- hash: "063"
  treatment: 1
  plot_number: 2006
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: IRT2006B1xx24
  span: 5
  sdi-12_address: "b"
  depth: 
  node: B
  field: LINEAR_SOYBEAN

- hash: "064"
  treatment: 1
  plot_number: 2006
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR2006B10624
  span: 5
  sdi-12_address: "4"
  depth: 6
  node: B
  field: LINEAR_SOYBEAN

- hash: "065"
  treatment: 1
  plot_number: 2006
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR2006B11824
  span: 5
  sdi-12_address: "5"
  depth: 18
  node: B
  field: LINEAR_SOYBEAN

- hash: "066"
  treatment: 1
  plot_number: 2006
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR2006B13024
  span: 5
  sdi-12_address: "6"
  depth: 30
  node: B
  field: LINEAR_SOYBEAN

- hash: "067"
  treatment: 1
  plot_number: 2006
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR2006B14224
  span: 5
  sdi-12_address: "7"
  depth: 42
  node: B
  field: LINEAR_SOYBEAN

- hash: "068"
  treatment: 4
  plot_number: 2012
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR2012B40624
  span: 5
  sdi-12_address: "8"
  depth: 6
  node: B
  field: LINEAR_SOYBEAN

- hash: "069"
  treatment: 4
  plot_number: 2012
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR2012B41824
  span: 5
  sdi-12_address: "9"
  depth: 18
  node: B
  field: LINEAR_SOYBEAN

- hash: "070"
  treatment: 4
  plot_number: 2012
  project_id: crop2cloud24
  dataset_id: node_b
  sensor_id: TDR2012B43024
  span: 5
  sdi-12_address: "a"
  depth: 30
  node: B
  field: LINEAR_SOYBEAN

# LINEAR_SOYBEAN Field Sensors (Node C)
# Total Sensors: 10 (2 IRT, 8 TDR)
- hash: "071"
  treatment: 1
  plot_number: 2023
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: IRT2023C1xx24
  span: 5
  sdi-12_address: "0"
  depth: 
  node: C
  field: LINEAR_SOYBEAN

- hash: "072"
  treatment: 1
  plot_number: 2023
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR2023C10624
  span: 5
  sdi-12_address: "1"
  depth: 6
  node: C
  field: LINEAR_SOYBEAN

- hash: "073"
  treatment: 1
  plot_number: 2023
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR2023C11824
  span: 5
  sdi-12_address: "2"
  depth: 18
  node: C
  field: LINEAR_SOYBEAN

- hash: "074"
  treatment: 1
  plot_number: 2023
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR2023C13024
  span: 5
  sdi-12_address: "3"
  depth: 30
  node: C
  field: LINEAR_SOYBEAN

- hash: "075"
  treatment: 1
  plot_number: 2023
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR2023C14224
  span: 5
  sdi-12_address: "4"
  depth: 42
  node: C
  field: LINEAR_SOYBEAN

- hash: "076"
  treatment: 1
  plot_number: 2015
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: IRT2015C1xx24
  span: 5
  sdi-12_address: "6"
  depth: 
  node: C
  field: LINEAR_SOYBEAN

- hash: "077"
  treatment: 1
  plot_number: 2015
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR2015C10624
  span: 5
  sdi-12_address: "7"
  depth: 6
  node: C
  field: LINEAR_SOYBEAN

- hash: "078"
  treatment: 1
  plot_number: 2015
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR2015C11824
  span: 5
  sdi-12_address: "8"
  depth: 18
  node: C
  field: LINEAR_SOYBEAN

- hash: "079"
  treatment: 1
  plot_number: 2015
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR2015C13024
  span: 5
  sdi-12_address: "9"
  depth: 30
  node: C
  field: LINEAR_SOYBEAN

- hash: "080"
  treatment: 1
  plot_number: 2015
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR2015C14224
  span: 5
  sdi-12_address: "a"
  depth: 42
  node: C
  field: LINEAR_SOYBEAN

- hash: "081"
  treatment: 3
  plot_number: 2018
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: IRT2018C3xx24
  span: 5
  sdi-12_address: "b"
  depth: 
  node: C
  field: LINEAR_SOYBEAN

- hash: "082"
  treatment: 3
  plot_number: 2020
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: IRT2020C3xx24
  span: 5
  sdi-12_address: "g"
  depth: 
  node: C
  field: LINEAR_SOYBEAN

- hash: "083"
  treatment: 2
  plot_number: 2026
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR2026C23024
  span: 5
  sdi-12_address: "c"
  depth: 30
  node: C
  field: LINEAR_SOYBEAN

- hash: "084"
  treatment: 2
  plot_number: 2026
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR2026C21824
  span: 5
  sdi-12_address: "d"
  depth: 18
  node: C
  field: LINEAR_SOYBEAN

- hash: "085"
  treatment: 2
  plot_number: 2026
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: TDR2026C20624
  span: 5
  sdi-12_address: "e"
  depth: 6
  node: C
  field: LINEAR_SOYBEAN

- hash: "086"
  treatment: 2
  plot_number: 2026
  project_id: crop2cloud24
  dataset_id: node_c
  sensor_id: IRT2026C2xx24
  span: 5
  sdi-12_address: "h"
  depth: 
  node: C
  field: LINEAR_SOYBEAN

  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  #         SOYBEAN FIELDS
  #~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
        </content>
    </file>
</directory>
    <directory name="data">
    <file>
        <name>LINEAR_CORN_trt1_plot_5006_20240719.csv</name>
        <path>data\LINEAR_CORN_trt1_plot_5006_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_CORN_trt1_plot_5010_20240719.csv</name>
        <path>data\LINEAR_CORN_trt1_plot_5010_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_CORN_trt1_plot_5023_20240719.csv</name>
        <path>data\LINEAR_CORN_trt1_plot_5023_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_CORN_trt2_plot_5003_20240719.csv</name>
        <path>data\LINEAR_CORN_trt2_plot_5003_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_CORN_trt2_plot_5012_20240719.csv</name>
        <path>data\LINEAR_CORN_trt2_plot_5012_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_CORN_trt2_plot_5026_20240719.csv</name>
        <path>data\LINEAR_CORN_trt2_plot_5026_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_CORN_trt3_plot_5001_20240719.csv</name>
        <path>data\LINEAR_CORN_trt3_plot_5001_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_CORN_trt3_plot_5018_20240719.csv</name>
        <path>data\LINEAR_CORN_trt3_plot_5018_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_CORN_trt3_plot_5020_20240719.csv</name>
        <path>data\LINEAR_CORN_trt3_plot_5020_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_CORN_trt4_plot_5007_20240719.csv</name>
        <path>data\LINEAR_CORN_trt4_plot_5007_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_CORN_trt4_plot_5009_20240719.csv</name>
        <path>data\LINEAR_CORN_trt4_plot_5009_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_CORN_trt4_plot_5027_20240719.csv</name>
        <path>data\LINEAR_CORN_trt4_plot_5027_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_SOYBEAN_trt1_plot_2006_20240719.csv</name>
        <path>data\LINEAR_SOYBEAN_trt1_plot_2006_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_SOYBEAN_trt1_plot_2015_20240719.csv</name>
        <path>data\LINEAR_SOYBEAN_trt1_plot_2015_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_SOYBEAN_trt1_plot_2023_20240719.csv</name>
        <path>data\LINEAR_SOYBEAN_trt1_plot_2023_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_SOYBEAN_trt2_plot_2001_20240719.csv</name>
        <path>data\LINEAR_SOYBEAN_trt2_plot_2001_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_SOYBEAN_trt2_plot_2011_20240719.csv</name>
        <path>data\LINEAR_SOYBEAN_trt2_plot_2011_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_SOYBEAN_trt2_plot_2026_20240719.csv</name>
        <path>data\LINEAR_SOYBEAN_trt2_plot_2026_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_SOYBEAN_trt3_plot_2003_20240719.csv</name>
        <path>data\LINEAR_SOYBEAN_trt3_plot_2003_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_SOYBEAN_trt3_plot_2018_20240719.csv</name>
        <path>data\LINEAR_SOYBEAN_trt3_plot_2018_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_SOYBEAN_trt3_plot_2020_20240719.csv</name>
        <path>data\LINEAR_SOYBEAN_trt3_plot_2020_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_SOYBEAN_trt4_plot_2009_20240719.csv</name>
        <path>data\LINEAR_SOYBEAN_trt4_plot_2009_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    <file>
        <name>LINEAR_SOYBEAN_trt4_plot_2012_20240719.csv</name>
        <path>data\LINEAR_SOYBEAN_trt4_plot_2012_20240719.csv</path>
        <content>Full content not provided</content>
    </file>
    </directory>
    <directory name="src">
    <file>
        <name>cwsi_th1.py</name>
        <path>src\cwsi_th1.py</path>
        <content>
import os
import pandas as pd
import numpy as np
import logging
from datetime import time

# Configuration
STEFAN_BOLTZMANN = 5.67e-8
CP = 1005
K = 0.41
CROP_HEIGHT = 1.6
SURFACE_ALBEDO = 0.23

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def celsius_to_kelvin(temp_celsius):
    return temp_celsius + 273.15

def saturated_vapor_pressure(temperature_celsius):
    return 0.6108 * np.exp(17.27 * temperature_celsius / (temperature_celsius + 237.3))

def vapor_pressure_deficit(temperature_celsius, relative_humidity):
    es = saturated_vapor_pressure(temperature_celsius)
    ea = es * (relative_humidity / 100)
    return es - ea

def net_radiation(solar_radiation, air_temp_celsius, canopy_temp_celsius, surface_albedo=0.23, emissivity_a=0.85, emissivity_c=0.98):
    air_temp_kelvin = celsius_to_kelvin(air_temp_celsius)
    canopy_temp_kelvin = celsius_to_kelvin(canopy_temp_celsius)
    Rns = (1 - surface_albedo) * solar_radiation
    Rnl = emissivity_c * STEFAN_BOLTZMANN * canopy_temp_kelvin**4 - emissivity_a * STEFAN_BOLTZMANN * air_temp_kelvin**4
    return Rns - Rnl

def soil_heat_flux(net_radiation):
    return net_radiation * 0.1

def aerodynamic_resistance(wind_speed, measurement_height, zero_plane_displacement, roughness_length):
    return (np.log((measurement_height - zero_plane_displacement) / roughness_length) * 
            np.log((measurement_height - zero_plane_displacement) / (roughness_length * 0.1))) / (K**2 * wind_speed)

def psychrometric_constant(atmospheric_pressure_pa):
    return (CP * atmospheric_pressure_pa) / (0.622 * 2.45e6)

def slope_saturation_vapor_pressure(temperature_celsius):
    return 4098 * saturated_vapor_pressure(temperature_celsius) / (temperature_celsius + 237.3)**2

def convert_wind_speed(u3, crop_height):
    z0 = 0.1 * crop_height
    return u3 * (np.log(2/z0) / np.log(3/z0))

def calculate_cwsi_th1(row, crop_height, surface_albedo=0.23):
    Ta = row['Ta_2m_Avg']
    RH = row['RH_2m_Avg']
    Rs = row['Solar_2m_Avg']
    u3 = row['WndAveSpd_3m']
    P = row['PresAvg_1pnt5m'] * 100
    Tc = row['canopy_temp']
    
    u2 = convert_wind_speed(u3, crop_height)
    
    VPD = vapor_pressure_deficit(Ta, RH)
    Rn = net_radiation(Rs, Ta, Tc, surface_albedo)
    G = soil_heat_flux(Rn)
    
    zero_plane_displacement = 0.67 * crop_height
    roughness_length = 0.123 * crop_height
    
    ra = aerodynamic_resistance(u2, 2, zero_plane_displacement, roughness_length)
    γ = psychrometric_constant(P)
    Δ = slope_saturation_vapor_pressure(Ta)
    
    ρ = P / (287.05 * celsius_to_kelvin(Ta))
    
    numerator = (Tc - Ta) - ((ra * (Rn - G)) / (ρ * CP)) + (VPD / γ)
    denominator = ((Δ + γ) * ra * (Rn - G)) / (ρ * CP * γ) + (VPD / γ)
    
    if denominator == 0:
        return None
    
    cwsi = numerator / denominator
    return cwsi if 0 <= cwsi <= 1.5 else None

def process_csv_file(file_path):
    logger.info(f"Processing file: {file_path}")
    
    # Read the CSV file
    df = pd.read_csv(file_path, parse_dates=['TIMESTAMP'])
    
    # Find the IRT column
    irt_column = next((col for col in df.columns if 'irt' in col.lower()), None)
    if not irt_column:
        logger.warning(f"No IRT column found in {file_path}")
        return None
    
    # Filter data between 12 PM and 5 PM
    df['time'] = df['TIMESTAMP'].dt.time
    mask = (df['time'] >= time(12, 0)) & (df['time'] <= time(17, 0))
    
    # Rename IRT column to 'canopy_temp' for CWSI calculation
    df.loc[mask, 'canopy_temp'] = df.loc[mask, irt_column]
    
    # Remove existing CWSI column if it exists
    if 'cwsi' in df.columns:
        df = df.drop(columns=['cwsi'])
    
    # Calculate CWSI only for the filtered rows
    df.loc[mask, 'cwsi'] = df.loc[mask].apply(lambda row: calculate_cwsi_th1(row, CROP_HEIGHT, SURFACE_ALBEDO), axis=1)
    
    # Remove temporary columns
    df = df.drop(columns=['time', 'canopy_temp'])
    
    # Save the updated DataFrame back to the same CSV file
    df.to_csv(file_path, index=False)
    logger.info(f"Updated CWSI values in file: {file_path}")
    
    return df

def main(input_folder):
    for root, _, files in os.walk(input_folder):
        for file in files:
            if file.endswith('.csv'):
                file_path = os.path.join(root, file)
                process_csv_file(file_path)

if __name__ == "__main__":
    input_folder = r"C:\Users\bnsoh2\OneDrive - University of Nebraska-Lincoln\Documents\Projects\masters-project\cwsi-swsi-et\data"
    main(input_folder)
        </content>
    </file>
    <file>
        <name>dat_to_csv.py</name>
        <path>src\dat_to_csv.py</path>
        <content>
import os
import re
import pandas as pd
import numpy as np
import yaml
from datetime import datetime
from pytz import timezone

def load_sensor_mapping(file_path):
    with open(file_path, 'r') as file:
        return yaml.safe_load(file)

def parse_dat_file(file_name):
    with open(file_name, "r") as file:
        lines = file.readlines()
    headers = lines[1].strip().split(",")
    data_lines = lines[4:]
    data = pd.DataFrame([line.strip().split(",") for line in data_lines], columns=headers)
    
    data.columns = data.columns.str.replace('"', "").str.replace("RECORD", "RecNbr")
    data.columns = data.columns.str.replace("_Avg", "")
    data = data.replace({"NAN": np.nan, '"NAN"': np.nan})
    data["TIMESTAMP"] = data["TIMESTAMP"].str.replace('"', "")
    
    for col in data.columns:
        if col != "TIMESTAMP":
            data[col] = pd.to_numeric(data[col], errors='coerce')
    
    data["TIMESTAMP"] = pd.to_datetime(data["TIMESTAMP"], errors="coerce")
    data = data[~data["TIMESTAMP"].isna()]
    
    data = data.set_index("TIMESTAMP")
    data.index = data.index.tz_localize("America/Chicago")
    
    # Correct column names if necessary
    if 'TDR5006B11724' in data.columns:
        data['TDR5006B11824'] = data['TDR5006B11724']
        data.drop('TDR5006B11724', axis=1, inplace=True)
    
    if 'TDR5026A23824' in data.columns:
        data['TDR5026A23024'] = data['TDR5026A23824']
        data.drop('TDR5026A23824', axis=1, inplace=True)
    
    # Resample to hourly data
    data_hourly = data.resample('1H').mean()
    
    return data_hourly.sort_index()  # Sort by timestamp

def get_dat_files(folder_path, crop_type):
    if crop_type == 'corn':
        patterns = [r'nodeA.*\.dat', r'nodeB.*\.dat', r'nodeC.*\.dat']
    elif crop_type == 'soybean':
        patterns = [r'SoyNodeA.*_NodeA\.dat', r'SoyNodeB.*_NodeB\.dat', r'SoyNodeC.*_NodeC\.dat']
    
    dat_files = []
    for file in os.listdir(folder_path):
        for pattern in patterns:
            if re.match(pattern, file, re.IGNORECASE):
                dat_files.append(os.path.join(folder_path, file))
                break
    return dat_files

def parse_weather_csv(filename):
    df = pd.read_csv(
        filename,
        header=1,
        skiprows=[2, 3],
        parse_dates=["TIMESTAMP"],
        date_format="%Y-%m-%d %H:%M:%S"
    )
    
    df = df.rename(columns=lambda x: x.strip())
    df["TIMESTAMP"] = pd.to_datetime(df["TIMESTAMP"], errors="coerce")
    df = df.dropna(subset=["TIMESTAMP"])
    df["TIMESTAMP"] = df["TIMESTAMP"].apply(lambda x: x.replace(tzinfo=timezone('America/Chicago')).astimezone(timezone('UTC')))
    df = df.set_index("TIMESTAMP")
    df = df.apply(pd.to_numeric, errors="coerce")

    # Select only the required weather columns
    weather_columns = ['Ta_2m_Avg', 'RH_2m_Avg', 'WndAveSpd_3m', 'WndAveDir_3m', 'PresAvg_1pnt5m', 'Solar_2m_Avg', 'Rain_1m_Tot', 'TaMax_2m', 'TaMin_2m', 'RHMax_2m', 'RHMin_2m']
    df = df[weather_columns]

    # Resample to hourly data
    df_hourly = df.resample('1H').mean()
    
    return df_hourly.sort_index()  # Sort by timestamp

def process_folder(folder_path, sensor_mapping, crop_type, output_folder, weather_data):
    dat_files = get_dat_files(folder_path, crop_type)
    
    for dat_file in dat_files:
        if os.path.exists(dat_file):
            print(f"Processing file: {dat_file}")
            df = parse_dat_file(dat_file)
            crop_specific_mapping = [sensor for sensor in sensor_mapping if sensor['field'] == f'LINEAR_{crop_type.upper()}']
            process_and_save_data(df, crop_specific_mapping, crop_type, output_folder, weather_data)
        else:
            print(f"File not found: {dat_file}")

def process_and_save_data(df, sensor_mapping, crop_type, output_folder, weather_data):
    sensor_groups = {}
    for sensor in sensor_mapping:
        key = (sensor['treatment'], sensor['plot_number'], sensor['field'])
        if key not in sensor_groups:
            sensor_groups[key] = []
        sensor_groups[key].append(sensor['sensor_id'])

    for (treatment, plot_number, field), sensors in sensor_groups.items():
        columns_to_save = ['TIMESTAMP'] + [s for s in sensors if s in df.columns]
        df_to_save = df.reset_index()[columns_to_save].dropna(subset=columns_to_save[1:], how='all')
        
        if not df_to_save.empty:
            # Merge with weather data
            df_to_save = df_to_save.set_index('TIMESTAMP').sort_index()
            merged_df = pd.merge(df_to_save, weather_data, left_index=True, right_index=True, how='outer')
            merged_df = merged_df.reset_index()

            file_name = f"{field}_trt{treatment}_plot_{plot_number}_{datetime.now().strftime('%Y%m%d')}.csv"
            output_path = os.path.join(output_folder, file_name)
            merged_df.to_csv(output_path, index=False)
            print(f"Saved data to {output_path}")
        else:
            print(f"No data to save for {field} plot {plot_number}")

def main(corn_folders, soybean_folders, sensor_mapping_path, output_folder, weather_csv_path):
    sensor_mapping = load_sensor_mapping(sensor_mapping_path)
    
    os.makedirs(output_folder, exist_ok=True)
    
    # Load and process weather data
    weather_data = parse_weather_csv(weather_csv_path)
    
    print("Processing corn data")
    for folder in corn_folders:
        print(f"Processing corn folder: {folder}")
        process_folder(folder, sensor_mapping, crop_type='corn', output_folder=output_folder, weather_data=weather_data)
    
    print("Processing soybean data")
    for folder in soybean_folders:
        print(f"Processing soybean folder: {folder}")
        process_folder(folder, sensor_mapping, crop_type='soybean', output_folder=output_folder, weather_data=weather_data)

if __name__ == "__main__":
    corn_folders = [
        r"C:\Users\bnsoh2\OneDrive - University of Nebraska-Lincoln\Projects\Students\Bryan Nsoh\Data\2024_data_corn_lnr\07-03-2024",
        r"C:\Users\bnsoh2\OneDrive - University of Nebraska-Lincoln\Projects\Students\Bryan Nsoh\Data\2024_data_corn_lnr\07-08-2024-discontinuous",
        r"C:\Users\bnsoh2\OneDrive - University of Nebraska-Lincoln\Projects\Students\Bryan Nsoh\Data\2024_data_corn_lnr\07-14-2024-discont-nodeC only",
        r"C:\Users\bnsoh2\OneDrive - University of Nebraska-Lincoln\Projects\Students\Bryan Nsoh\Data\2024_data_corn_lnr\07-15-2024-discont-unsure",
        r"C:\Users\bnsoh2\OneDrive - University of Nebraska-Lincoln\Projects\Students\Bryan Nsoh\Data\2024_data_corn_lnr\07-19-2024"
    ]
    soybean_folders = [
        r"C:\Users\bnsoh2\OneDrive - University of Nebraska-Lincoln\Projects\Students\Bryan Nsoh\Data\Soybean Lnr\07-15-24",
        r"C:\Users\bnsoh2\OneDrive - University of Nebraska-Lincoln\Projects\Students\Bryan Nsoh\Data\Soybean Lnr\07-19-2024"
    ]
    sensor_mapping_path = r"C:\Users\bnsoh2\OneDrive - University of Nebraska-Lincoln\Documents\Projects\masters-project\cwsi-swsi-et\sensor_mapping.yaml"
    output_folder = r"C:\Users\bnsoh2\OneDrive - University of Nebraska-Lincoln\Documents\Projects\masters-project\cwsi-swsi-et\data"
    weather_csv_path = r"C:\Users\bnsoh2\Downloads\North_Platte_3SW_Beta_1min (8).csv"
    
    main(corn_folders, soybean_folders, sensor_mapping_path, output_folder, weather_csv_path)
        </content>
    </file>
    <file>
        <name>et.py</name>
        <path>src\et.py</path>
        <content>
import os
import pandas as pd
import numpy as np
import pyet
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Metadata
ELEVATION = 876  # meters
LATITUDE = 41.15  # degrees
LONGITUDE = -100.77  # degrees
WIND_HEIGHT = 3  # meters
STEFAN_BOLTZMANN = 5.67e-8
CP = 1005
GRAVITY = 9.81
K = 0.41
CROP_HEIGHT = 1.6
SURFACE_ALBEDO = 0.23

def calculate_et(df):
    # Resample to daily, handling missing data
    df_daily = df.set_index('TIMESTAMP').resample('D').mean()
    
    required_columns = ['Ta_2m_Avg', 'TaMax_2m', 'TaMin_2m', 'RHMax_2m', 'RHMin_2m', 'WndAveSpd_3m', 'Solar_2m_Avg']
    df_daily = df_daily.dropna(subset=required_columns)
    
    if df_daily.empty:
        logger.warning("Dataframe is empty after resampling and dropping NaN values.")
        return pd.DataFrame(columns=['TIMESTAMP', 'et'])
    
    # Convert solar radiation to MJ/m^2/day
    df_daily['Solar_2m_Avg_MJ'] = df_daily['Solar_2m_Avg'] * 0.0864
    
    lat_rad = LATITUDE * np.pi / 180
    
    # Prepare input data
    inputs = {
        'tmean': df_daily['Ta_2m_Avg'],
        'wind': df_daily['WndAveSpd_3m'],
        'rs': df_daily['Solar_2m_Avg_MJ'],
        'tmax': df_daily['TaMax_2m'],
        'tmin': df_daily['TaMin_2m'],
        'rh': (df_daily['RHMax_2m'] + df_daily['RHMin_2m']) / 2,
        'elevation': ELEVATION,
        'lat': lat_rad
    }
    
    # Calculate ET
    df_daily['et'] = pyet.combination.pm_asce(**inputs)
    
    # Reset index to get TIMESTAMP as a column and return only TIMESTAMP and et
    return df_daily.reset_index()[['TIMESTAMP', 'et']]

def process_csv_file(file_path):
    logger.info(f"Processing file for ET calculation: {file_path}")
    
    df = pd.read_csv(file_path, parse_dates=['TIMESTAMP'])
    
    et_df = calculate_et(df)
    
    if not et_df.empty:
        # Merge ET data back into original dataframe
        df = pd.merge(df, et_df, on='TIMESTAMP', how='left')
        
        # Log ET statistics
        valid_et = df['et'].dropna()
        if len(valid_et) > 0:
            logger.info(f"ET stats - Count: {len(valid_et)}, Mean: {valid_et.mean():.4f}, Min: {valid_et.min():.4f}, Max: {valid_et.max():.4f}")
        else:
            logger.info("No valid ET values calculated")
        
        # Save updated dataframe
        df.to_csv(file_path, index=False)
        logger.info(f"Updated ET values in file: {file_path}")
    else:
        logger.warning(f"No ET values calculated for file: {file_path}")
    
    return df

def main(input_folder):
    for root, _, files in os.walk(input_folder):
        for file in files:
            if file.endswith('.csv'):
                file_path = os.path.join(root, file)
                process_csv_file(file_path)

if __name__ == "__main__":
    input_folder = r"C:\Users\bnsoh2\OneDrive - University of Nebraska-Lincoln\Documents\Projects\masters-project\cwsi-swsi-et\data"
    main(input_folder)
        </content>
    </file>
    <file>
        <name>fuzz.py</name>
        <path>src\fuzz.py</path>
        <content>
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from skfuzzy import control as ctrl
import skfuzzy as fuzz
from datetime import datetime, timedelta
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class FuzzyIrrigationController:
    def __init__(self):
        self.setup_fuzzy_system()

    def setup_fuzzy_system(self):
        # Define input ranges
        x_et = np.arange(0, 20, 0.1)
        x_swsi = np.arange(0, 1, 0.01)
        x_cwsi = np.arange(0, 1, 0.01)
        x_irrigation = np.arange(0, 1, 0.01)
    
        # Create fuzzy variables
        self.et = ctrl.Antecedent(x_et, 'et')
        self.swsi = ctrl.Antecedent(x_swsi, 'swsi')
        self.cwsi = ctrl.Antecedent(x_cwsi, 'cwsi')
        self.irrigation = ctrl.Consequent(x_irrigation, 'irrigation')
    
        # Define membership functions
        self.et['very_low'] = fuzz.trimf(x_et, [0, 0, 5])
        self.et['low'] = fuzz.trimf(x_et, [0, 5, 10])
        self.et['medium'] = fuzz.trimf(x_et, [5, 10, 15])
        self.et['high'] = fuzz.trimf(x_et, [10, 15, 20])
        self.et['very_high'] = fuzz.trimf(x_et, [15, 20, 20])
    
        self.swsi['very_wet'] = fuzz.trimf(x_swsi, [0, 0, 0.25])
        self.swsi['wet'] = fuzz.trimf(x_swsi, [0, 0.25, 0.5])
        self.swsi['normal'] = fuzz.trimf(x_swsi, [0.25, 0.5, 0.75])
        self.swsi['dry'] = fuzz.trimf(x_swsi, [0.5, 0.75, 1])
        self.swsi['very_dry'] = fuzz.trimf(x_swsi, [0.75, 1, 1])
    
        self.cwsi['no_stress'] = fuzz.trimf(x_cwsi, [0, 0, 0.25])
        self.cwsi['low_stress'] = fuzz.trimf(x_cwsi, [0, 0.25, 0.5])
        self.cwsi['moderate_stress'] = fuzz.trimf(x_cwsi, [0.25, 0.5, 0.75])
        self.cwsi['high_stress'] = fuzz.trimf(x_cwsi, [0.5, 0.75, 1])
        self.cwsi['severe_stress'] = fuzz.trimf(x_cwsi, [0.75, 1, 1])
    
        self.irrigation['none'] = fuzz.trimf(x_irrigation, [0, 0, 0.2])
        self.irrigation['very_low'] = fuzz.trimf(x_irrigation, [0, 0.2, 0.4])
        self.irrigation['low'] = fuzz.trimf(x_irrigation, [0.2, 0.4, 0.6])
        self.irrigation['medium'] = fuzz.trimf(x_irrigation, [0.4, 0.6, 0.8])
        self.irrigation['high'] = fuzz.trimf(x_irrigation, [0.6, 0.8, 1])
        self.irrigation['very_high'] = fuzz.trimf(x_irrigation, [0.8, 1, 1])
    
        # Define fuzzy rules
        rules = [
            ctrl.Rule(self.cwsi['severe_stress'], self.irrigation['very_high']),
            ctrl.Rule(self.cwsi['high_stress'], self.irrigation['high']),
            ctrl.Rule(self.cwsi['moderate_stress'], self.irrigation['medium']),
            ctrl.Rule(self.cwsi['low_stress'], self.irrigation['low']),
            ctrl.Rule(self.cwsi['no_stress'], self.irrigation['very_low']),
            
            ctrl.Rule(self.swsi['very_dry'], self.irrigation['very_high']),
            ctrl.Rule(self.swsi['dry'], self.irrigation['high']),
            ctrl.Rule(self.swsi['normal'], self.irrigation['medium']),
            ctrl.Rule(self.swsi['wet'], self.irrigation['low']),
            ctrl.Rule(self.swsi['very_wet'], self.irrigation['none']),
            
            ctrl.Rule(self.cwsi['severe_stress'] & self.swsi['very_dry'], self.irrigation['very_high']),
            ctrl.Rule(self.cwsi['high_stress'] & self.swsi['dry'], self.irrigation['high']),
            ctrl.Rule(self.cwsi['moderate_stress'] & self.swsi['normal'], self.irrigation['medium']),
            ctrl.Rule(self.cwsi['low_stress'] & self.swsi['wet'], self.irrigation['low']),
            ctrl.Rule(self.cwsi['no_stress'] & self.swsi['very_wet'], self.irrigation['none']),
            
            ctrl.Rule(self.et['very_high'] & self.cwsi['high_stress'], self.irrigation['high']),
            ctrl.Rule(self.et['high'] & self.swsi['dry'], self.irrigation['medium']),
            ctrl.Rule(self.et['medium'] & (self.cwsi['moderate_stress'] | self.swsi['normal']), self.irrigation['medium']),
            ctrl.Rule(self.et['low'] & (self.cwsi['low_stress'] | self.swsi['wet']), self.irrigation['low']),
            ctrl.Rule(self.et['very_low'] & (self.cwsi['no_stress'] | self.swsi['very_wet']), self.irrigation['none']),
        ]
    
        # Create and simulate control system
        self.irrigation_ctrl = ctrl.ControlSystem(rules)
        self.irrigation_sim = ctrl.ControlSystemSimulation(self.irrigation_ctrl)

    def get_recent_values(self, series, n_days=3):
        end_date = pd.Timestamp.now().floor('D')
        start_date = end_date - pd.Timedelta(days=n_days)
        
        # Ensure the series index is timezone-naive
        if series.index.tz is not None:
            series.index = series.index.tz_localize(None)
        
        recent_data = series.loc[start_date:end_date]
        return recent_data, start_date, end_date

    def compute_irrigation(self, df, n_days=3):
        # Compute inputs for fuzzy system
        et_data, et_start, et_end = self.get_recent_values(df['et'], n_days)
        swsi_data, swsi_start, swsi_end = self.get_recent_values(df['swsi'], n_days)
        cwsi_data, cwsi_start, cwsi_end = self.get_recent_values(df['cwsi'], n_days)

        et_avg = et_data.mean()
        swsi_avg = swsi_data.mean()
        cwsi_max = min(cwsi_data.max(), 1)  # Cap CWSI at 1

        # Log the values used for decision making
        logger.info(f"\nValues used for irrigation decision:")
        logger.info(f"ET Average: {et_avg:.2f} (from {et_start} to {et_end})")
        logger.info(f"SWSI Average: {swsi_avg:.2f} (from {swsi_start} to {swsi_end})")
        logger.info(f"CWSI Maximum: {cwsi_max:.2f} (from {cwsi_start} to {cwsi_end})")

        # Set inputs for fuzzy system
        self.irrigation_sim.input['et'] = et_avg
        self.irrigation_sim.input['swsi'] = swsi_avg
        self.irrigation_sim.input['cwsi'] = cwsi_max

        # Compute output
        self.irrigation_sim.compute()

        irrigation_amount = self.irrigation_sim.output['irrigation']

        logger.info(f"\nRecommended Irrigation Amount: {irrigation_amount:.2f} inches")

        return irrigation_amount, et_avg, swsi_avg, cwsi_max

def process_csv_file(file_path, controller):
    logger.info(f"Processing file for irrigation recommendation: {file_path}")
    
    df = pd.read_csv(file_path, parse_dates=['TIMESTAMP'])
    df.set_index('TIMESTAMP', inplace=True)
    
    irrigation_amount, et_avg, swsi_avg, cwsi_max = controller.compute_irrigation(df)
    
    plot_number = file_path.split('_')[-2]  # Assuming the plot number is the second-to-last part of the filename
    crop_type = 'corn' if 'CORN' in file_path else 'soybean'
    
    return {
        'plot': plot_number,
        'crop': crop_type,
        'irrigation': irrigation_amount,
        'et_avg': et_avg,
        'swsi_avg': swsi_avg,
        'cwsi_max': cwsi_max
    }

def main(input_folder, output_file):
    controller = FuzzyIrrigationController()
    recommendations = []

    for root, _, files in os.walk(input_folder):
        for file in files:
            if file.endswith('.csv') and ('CORN' in file or 'SOYBEAN' in file) and 'trt1' in file:
                file_path = os.path.join(root, file)
                result = process_csv_file(file_path, controller)
                recommendations.append(result)

    # Create recommendations DataFrame and save to CSV
    recommendations_df = pd.DataFrame(recommendations)
    recommendations_df.to_csv(output_file, index=False)
    logger.info(f"Recommendations saved to {output_file}")

if __name__ == "__main__":
    input_folder = r"C:\Users\bnsoh2\OneDrive - University of Nebraska-Lincoln\Documents\Projects\masters-project\cwsi-swsi-et\data"
    output_file = r"C:\Users\bnsoh2\OneDrive - University of Nebraska-Lincoln\Documents\Projects\masters-project\cwsi-swsi-et\recommendations.csv"
    main(input_folder, output_file)
        </content>
    </file>
    <file>
        <name>swsi.py</name>
        <path>src\swsi.py</path>
        <content>
import os
import pandas as pd
import numpy as np
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

SOIL_DATA = {
    '8815': {'fc': 0.269, 'pwp': 0.115},
    '8816': {'fc': 0.279, 'pwp': 0.126},
    '8869': {'fc': 0.291, 'pwp': 0.143}
}
AVG_FC = np.mean([data['fc'] for data in SOIL_DATA.values()])
AVG_PWP = np.mean([data['pwp'] for data in SOIL_DATA.values()])
MAD = 0.45

def calculate_soil_properties():
    fc = AVG_FC
    pwp = AVG_PWP
    awc = fc - pwp
    vwct = fc - MAD * awc
    return fc, pwp, awc, vwct

def calculate_swsi(vwc_values):
    valid_vwc = [vwc/100 for vwc in vwc_values if pd.notna(vwc) and vwc != 0]
    
    if len(valid_vwc) < 1:
        return None

    avg_vwc = np.mean(valid_vwc)
    fc, pwp, awc, vwct = calculate_soil_properties()
    
    if avg_vwc < vwct:
        return (vwct - avg_vwc) / (vwct - pwp)
    else:
        return 0

def process_csv_file(file_path):
    logger.info(f"Processing file: {file_path}")
    
    df = pd.read_csv(file_path, parse_dates=['TIMESTAMP'])
    
    tdr_columns = [col for col in df.columns if 'TDR' in col]
    if not tdr_columns:
        logger.warning(f"No TDR columns found in {file_path}")
        return None
    
    df['all_tdr_invalid'] = (df[tdr_columns] == 0).all(axis=1) | df[tdr_columns].isnull().all(axis=1)
    df_filtered = df[~df['all_tdr_invalid']].copy()  # Create a copy to avoid SettingWithCopyWarning
    
    df_filtered['swsi'] = df_filtered[tdr_columns].apply(calculate_swsi, axis=1)
    df.loc[df_filtered.index, 'swsi'] = df_filtered['swsi']  # Use .loc to avoid SettingWithCopyWarning
    df = df.drop(columns=['all_tdr_invalid'])
    
    non_zero_tdr = df_filtered[tdr_columns].values.flatten()
    non_zero_tdr = non_zero_tdr[~np.isnan(non_zero_tdr) & (non_zero_tdr != 0)]  # Remove NaN and zero values
    
    valid_swsi = df_filtered['swsi'].dropna()
    
    if len(non_zero_tdr) > 0:
        logger.info(f"TDR stats - Count: {len(non_zero_tdr)}, Mean: {np.mean(non_zero_tdr):.4f}, Min: {np.min(non_zero_tdr):.4f}, Max: {np.max(non_zero_tdr):.4f}")
    else:
        logger.info("No valid TDR values found")
    
    if len(valid_swsi) > 0:
        logger.info(f"SWSI stats - Count: {len(valid_swsi)}, Mean: {valid_swsi.mean():.4f}, Min: {valid_swsi.min():.4f}, Max: {valid_swsi.max():.4f}")
    else:
        logger.info("No valid SWSI values calculated")
    
    df.to_csv(file_path, index=False)
    logger.info(f"Updated SWSI values in file: {file_path}")
    
    return df

def main(input_folder):
    for root, _, files in os.walk(input_folder):
        for file in files:
            if file.endswith('.csv'):
                file_path = os.path.join(root, file)
                process_csv_file(file_path)

if __name__ == "__main__":
    input_folder = r"C:\Users\bnsoh2\OneDrive - University of Nebraska-Lincoln\Documents\Projects\masters-project\cwsi-swsi-et\data"
    main(input_folder)
        </content>
    </file>
    </directory>
</repository_structure>
